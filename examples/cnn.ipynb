{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bdce7130ac6627e",
   "metadata": {
    "collapsed": false,
    "id": "5bdce7130ac6627e"
   },
   "source": [
    "# 🧠 CNN for Multi-label Depression Symptom Classification (ReDSM5)\n",
    "\n",
    "This notebook shows how to train a simple Convolutional Neural Network (CNN) for **multi-label text classification** on the `ReDSM5` dataset, a Reddit corpus annotated with sentence-level DSM-5 depression symptoms.\n",
    "\n",
    "The workflow includes:\n",
    "- Loading and preprocessing the data,\n",
    "- Tokenizing the text and converting it to padded sequences,\n",
    "- Building and training a 1D CNN model using Keras,\n",
    "- Evaluating performance with precision, recall, F1-score, and accuracy metrics.\n",
    "\n",
    "Although CNNs are simpler than transformers like BERT, they still serve as useful baselines for capturing local patterns in text (e.g., n-gram-like features). This notebook provides a fully reproducible pipeline for benchmarking and educational purposes.\n",
    "\n",
    "> 🧪 This is one of the baseline models reported in the ReDSM5 paper. Use it to replicate results or explore light-weight alternatives to transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd9619c",
   "metadata": {},
   "source": [
    "## 📦 Importing Required Libraries\n",
    "\n",
    "We start by importing all the necessary libraries for:\n",
    "- **Data handling**: `pandas`, `sklearn`,\n",
    "- **Text preprocessing**: Keras's `Tokenizer` and `pad_sequences`,\n",
    "- **Model building**: `Sequential`, `Embedding`, `Conv1D`, and pooling/dense layers from Keras,\n",
    "- **Metrics and preprocessing**: for multi-label classification.\n",
    "\n",
    "This setup allows us to implement and train a CNN model for detecting multiple DSM-5 depression symptoms from Reddit posts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2b6c9",
   "metadata": {},
   "source": [
    "## 📊 Loading and Preprocessing the Dataset\n",
    "\n",
    "We load the `ReDSM5` dataset from a CSV file. Each record contains:\n",
    "- a Reddit post (`text`),\n",
    "- a list of annotated DSM-5 symptom labels (`labels`),\n",
    "- and a clinical explanation (not used here).\n",
    "\n",
    "We convert the semicolon-separated label string into Python lists and then apply `MultiLabelBinarizer` to convert those lists into binary vectors suitable for training. This format supports multi-label classification, where each post may have one or more active labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b464897186e2ad59",
   "metadata": {
    "id": "b464897186e2ad59"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"data/redsm5.csv\")\n",
    "data[\"labels\"] = data[\"labels\"].apply(lambda x: x.split(\";\"))  # Convert labels to list\n",
    "\n",
    "# MultiLabel Binarization\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data[\"labels\"])\n",
    "texts = data[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74100054",
   "metadata": {},
   "source": [
    "## ✂️ Splitting Data into Train and Test Sets\n",
    "\n",
    "We divide the dataset into training (80%) and testing (20%) subsets using `train_test_split`. This ensures that model evaluation is done on unseen data, providing a realistic sense of performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e6c006e5ad758",
   "metadata": {
    "id": "650e6c006e5ad758"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c485a9e",
   "metadata": {},
   "source": [
    "## 🔡 Text Tokenization and Padding\n",
    "\n",
    "To prepare the text for input into a neural network:\n",
    "1. We tokenize each post using Keras’s `Tokenizer`, which assigns an integer to every unique word.\n",
    "2. The posts are converted into sequences of word indices.\n",
    "3. We pad these sequences to a fixed maximum length (`512` tokens), ensuring that all input examples are the same size and compatible with batch training.\n",
    "\n",
    "Padding is done post-truncation to maintain temporal structure near the end of each post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734826f265f6e05",
   "metadata": {
    "id": "1734826f265f6e05"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "maxlen = 512\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=maxlen)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b655285",
   "metadata": {},
   "source": [
    "## 🧱 Building the CNN Model\n",
    "\n",
    "We define a lightweight convolutional neural network (CNN) architecture suitable for multi-label text classification:\n",
    "- **Embedding layer** maps word indices to dense vectors.\n",
    "- **Conv1D layer** captures local n-gram patterns using sliding filters.\n",
    "- **Global Max Pooling** reduces the output to the most important features across time.\n",
    "- **Dense layers** introduce non-linear transformations.\n",
    "- **Final layer with sigmoid** produces one probability per symptom class, enabling multi-label outputs.\n",
    "\n",
    "This CNN structure provides a strong and efficient baseline for text classification tasks without transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d7d9a7c24bd03",
   "metadata": {
    "id": "be6d7d9a7c24bd03"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation=\"relu\"))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(len(mlb.classes_), activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ac6e8",
   "metadata": {},
   "source": [
    "## 🧪 Compiling and Training the CNN Model\n",
    "\n",
    "We compile the CNN model using:\n",
    "- `binary_crossentropy` loss (standard for multi-label classification),\n",
    "- `adam` optimizer for efficient training,\n",
    "- and accuracy as the monitored metric (though limited in multi-label settings).\n",
    "\n",
    "We train the model for 100 epochs using a validation split of 20%. Keras automatically shuffles the training data and tracks both training and validation metrics across epochs. This setup allows us to monitor learning progress and detect overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WMCSuhohTc-Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMCSuhohTc-Y",
    "outputId": "2ffad66d-e06c-4aaf-a936-aeddf8fe05a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.1867 - loss: 0.6202 - val_accuracy: 0.2647 - val_loss: 0.3458\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2575 - loss: 0.3434 - val_accuracy: 0.1891 - val_loss: 0.3188\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2608 - loss: 0.3244 - val_accuracy: 0.2647 - val_loss: 0.3138\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2796 - loss: 0.3174 - val_accuracy: 0.2605 - val_loss: 0.3132\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3063 - loss: 0.3150 - val_accuracy: 0.2647 - val_loss: 0.3141\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3067 - loss: 0.3054 - val_accuracy: 0.2605 - val_loss: 0.3124\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3826 - loss: 0.2877 - val_accuracy: 0.3235 - val_loss: 0.3042\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5419 - loss: 0.2670 - val_accuracy: 0.3571 - val_loss: 0.2952\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6410 - loss: 0.2432 - val_accuracy: 0.3739 - val_loss: 0.2862\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7360 - loss: 0.2049 - val_accuracy: 0.3487 - val_loss: 0.2831\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8113 - loss: 0.1672 - val_accuracy: 0.3739 - val_loss: 0.2856\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8553 - loss: 0.1228 - val_accuracy: 0.3782 - val_loss: 0.2917\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.0988 - val_accuracy: 0.4034 - val_loss: 0.2945\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8838 - loss: 0.0765 - val_accuracy: 0.4118 - val_loss: 0.3038\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9046 - loss: 0.0567 - val_accuracy: 0.4076 - val_loss: 0.3167\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9171 - loss: 0.0457 - val_accuracy: 0.4118 - val_loss: 0.3483\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9049 - loss: 0.0356 - val_accuracy: 0.3824 - val_loss: 0.3445\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9268 - loss: 0.0282 - val_accuracy: 0.4286 - val_loss: 0.3531\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9288 - loss: 0.0222 - val_accuracy: 0.4202 - val_loss: 0.3722\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9368 - loss: 0.0191 - val_accuracy: 0.4328 - val_loss: 0.3843\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9346 - loss: 0.0160 - val_accuracy: 0.4160 - val_loss: 0.3882\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9311 - loss: 0.0112 - val_accuracy: 0.4454 - val_loss: 0.4024\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9311 - loss: 0.0101 - val_accuracy: 0.4076 - val_loss: 0.4256\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9276 - loss: 0.0098 - val_accuracy: 0.4370 - val_loss: 0.4231\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9339 - loss: 0.0074 - val_accuracy: 0.4412 - val_loss: 0.4203\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9340 - loss: 0.0069 - val_accuracy: 0.4370 - val_loss: 0.4318\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9510 - loss: 0.0071 - val_accuracy: 0.4370 - val_loss: 0.4602\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9115 - loss: 0.0053 - val_accuracy: 0.4286 - val_loss: 0.4483\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9342 - loss: 0.0049 - val_accuracy: 0.4244 - val_loss: 0.4366\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9412 - loss: 0.0041 - val_accuracy: 0.4370 - val_loss: 0.4788\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9143 - loss: 0.0045 - val_accuracy: 0.4370 - val_loss: 0.4628\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9326 - loss: 0.0033 - val_accuracy: 0.4202 - val_loss: 0.4950\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.0041 - val_accuracy: 0.4034 - val_loss: 0.4742\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9114 - loss: 0.0027 - val_accuracy: 0.4412 - val_loss: 0.4993\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.0030 - val_accuracy: 0.4076 - val_loss: 0.5092\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.0034 - val_accuracy: 0.4076 - val_loss: 0.4971\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9305 - loss: 0.0028 - val_accuracy: 0.4202 - val_loss: 0.4916\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 0.0043 - val_accuracy: 0.4076 - val_loss: 0.5015\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.0033 - val_accuracy: 0.3866 - val_loss: 0.4986\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.0023 - val_accuracy: 0.4454 - val_loss: 0.5144\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9135 - loss: 0.0037 - val_accuracy: 0.3782 - val_loss: 0.5406\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.0022 - val_accuracy: 0.4496 - val_loss: 0.5085\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9142 - loss: 0.0021 - val_accuracy: 0.3824 - val_loss: 0.5426\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9610 - loss: 0.0013 - val_accuracy: 0.4160 - val_loss: 0.5320\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9287 - loss: 0.0017 - val_accuracy: 0.3866 - val_loss: 0.5235\n",
      "Epoch 46/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.0029 - val_accuracy: 0.4202 - val_loss: 0.5362\n",
      "Epoch 47/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9291 - loss: 0.0021 - val_accuracy: 0.4454 - val_loss: 0.5471\n",
      "Epoch 48/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9321 - loss: 0.0028 - val_accuracy: 0.4328 - val_loss: 0.5398\n",
      "Epoch 49/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9203 - loss: 0.0021 - val_accuracy: 0.4244 - val_loss: 0.5383\n",
      "Epoch 50/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9358 - loss: 0.0017 - val_accuracy: 0.4496 - val_loss: 0.5469\n",
      "Epoch 51/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9228 - loss: 9.0451e-04 - val_accuracy: 0.4202 - val_loss: 0.5344\n",
      "Epoch 52/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9579 - loss: 0.0021 - val_accuracy: 0.4412 - val_loss: 0.5483\n",
      "Epoch 53/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9195 - loss: 7.5549e-04 - val_accuracy: 0.4370 - val_loss: 0.5844\n",
      "Epoch 54/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9486 - loss: 0.0020 - val_accuracy: 0.4370 - val_loss: 0.5342\n",
      "Epoch 55/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9502 - loss: 0.0013 - val_accuracy: 0.4412 - val_loss: 0.5539\n",
      "Epoch 56/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9156 - loss: 8.7291e-04 - val_accuracy: 0.4244 - val_loss: 0.5463\n",
      "Epoch 57/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9514 - loss: 0.0018 - val_accuracy: 0.4244 - val_loss: 0.5475\n",
      "Epoch 58/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9162 - loss: 0.0016 - val_accuracy: 0.4454 - val_loss: 0.5593\n",
      "Epoch 59/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9160 - loss: 0.0018 - val_accuracy: 0.4118 - val_loss: 0.5674\n",
      "Epoch 60/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9545 - loss: 9.9721e-04 - val_accuracy: 0.4244 - val_loss: 0.5703\n",
      "Epoch 61/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9309 - loss: 0.0016 - val_accuracy: 0.3908 - val_loss: 0.5702\n",
      "Epoch 62/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9428 - loss: 9.7334e-04 - val_accuracy: 0.4160 - val_loss: 0.5741\n",
      "Epoch 63/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9316 - loss: 0.0023 - val_accuracy: 0.4412 - val_loss: 0.5488\n",
      "Epoch 64/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9255 - loss: 0.0013 - val_accuracy: 0.4118 - val_loss: 0.5810\n",
      "Epoch 65/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9335 - loss: 0.0033 - val_accuracy: 0.4118 - val_loss: 0.5733\n",
      "Epoch 66/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9428 - loss: 0.0012 - val_accuracy: 0.4454 - val_loss: 0.5719\n",
      "Epoch 67/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 0.0017 - val_accuracy: 0.3992 - val_loss: 0.5890\n",
      "Epoch 68/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.0013 - val_accuracy: 0.4286 - val_loss: 0.5991\n",
      "Epoch 69/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9466 - loss: 0.0013 - val_accuracy: 0.4412 - val_loss: 0.5619\n",
      "Epoch 70/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9354 - loss: 0.0014 - val_accuracy: 0.4412 - val_loss: 0.5611\n",
      "Epoch 71/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9319 - loss: 0.0014 - val_accuracy: 0.4118 - val_loss: 0.5727\n",
      "Epoch 72/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9526 - loss: 0.0011 - val_accuracy: 0.4370 - val_loss: 0.5846\n",
      "Epoch 73/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9201 - loss: 0.0017 - val_accuracy: 0.4454 - val_loss: 0.5632\n",
      "Epoch 74/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9223 - loss: 6.4453e-04 - val_accuracy: 0.4454 - val_loss: 0.5660\n",
      "Epoch 75/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.0012 - val_accuracy: 0.4244 - val_loss: 0.5838\n",
      "Epoch 76/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9308 - loss: 0.0016 - val_accuracy: 0.4454 - val_loss: 0.5849\n",
      "Epoch 77/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9472 - loss: 0.0018 - val_accuracy: 0.4538 - val_loss: 0.6487\n",
      "Epoch 78/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9436 - loss: 0.0013 - val_accuracy: 0.4328 - val_loss: 0.5813\n",
      "Epoch 79/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9234 - loss: 0.0020 - val_accuracy: 0.4580 - val_loss: 0.6074\n",
      "Epoch 80/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9103 - loss: 0.0013 - val_accuracy: 0.4076 - val_loss: 0.6027\n",
      "Epoch 81/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.0019 - val_accuracy: 0.4454 - val_loss: 0.5644\n",
      "Epoch 82/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9225 - loss: 0.0012 - val_accuracy: 0.4202 - val_loss: 0.5972\n",
      "Epoch 83/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9549 - loss: 0.0023 - val_accuracy: 0.4286 - val_loss: 0.5714\n",
      "Epoch 84/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.0014 - val_accuracy: 0.4454 - val_loss: 0.6277\n",
      "Epoch 85/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9213 - loss: 0.0013 - val_accuracy: 0.4286 - val_loss: 0.5663\n",
      "Epoch 86/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9365 - loss: 8.4525e-04 - val_accuracy: 0.4412 - val_loss: 0.6171\n",
      "Epoch 87/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9529 - loss: 9.0183e-04 - val_accuracy: 0.4370 - val_loss: 0.6039\n",
      "Epoch 88/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9157 - loss: 0.0010 - val_accuracy: 0.4286 - val_loss: 0.5849\n",
      "Epoch 89/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 7.5638e-04 - val_accuracy: 0.3992 - val_loss: 0.6188\n",
      "Epoch 90/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9714 - loss: 4.1895e-04 - val_accuracy: 0.4244 - val_loss: 0.6029\n",
      "Epoch 91/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9270 - loss: 4.2291e-04 - val_accuracy: 0.4370 - val_loss: 0.5911\n",
      "Epoch 92/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 6.2022e-04 - val_accuracy: 0.4202 - val_loss: 0.6139\n",
      "Epoch 93/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9233 - loss: 4.6784e-04 - val_accuracy: 0.4202 - val_loss: 0.5988\n",
      "Epoch 94/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9601 - loss: 6.1485e-04 - val_accuracy: 0.4244 - val_loss: 0.6169\n",
      "Epoch 95/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9170 - loss: 6.5558e-04 - val_accuracy: 0.4244 - val_loss: 0.6005\n",
      "Epoch 96/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.0013 - val_accuracy: 0.4202 - val_loss: 0.6123\n",
      "Epoch 97/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9241 - loss: 0.0027 - val_accuracy: 0.4118 - val_loss: 0.6056\n",
      "Epoch 98/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9523 - loss: 9.6531e-04 - val_accuracy: 0.4370 - val_loss: 0.6153\n",
      "Epoch 99/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9126 - loss: 4.0694e-04 - val_accuracy: 0.4370 - val_loss: 0.6090\n",
      "Epoch 100/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9306 - loss: 5.9425e-04 - val_accuracy: 0.4202 - val_loss: 0.6192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e7d9e786250>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_padded, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355bb8f",
   "metadata": {},
   "source": [
    "## 🔍 Predicting on the Test Set\n",
    "\n",
    "After training, we use the trained CNN to predict the labels for the test set. Each prediction is a probability for each class, which we threshold at `0.5` to produce binary outputs.\n",
    "\n",
    "This binary matrix is used to assess how well the model identifies the presence or absence of each depression symptom in previously unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lX6FJwkOTg24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lX6FJwkOTg24",
    "outputId": "24453e58-b7ed-48b9-a3f2-28a99c32742b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(X_test_padded) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bda4fa",
   "metadata": {},
   "source": [
    "## 📊 Classification Metrics\n",
    "\n",
    "We evaluate the model using the `classification_report` and `accuracy_score` from `scikit-learn`. The metrics include:\n",
    "- **Precision, Recall, and F1-score** per symptom class,\n",
    "- **Micro, Macro, and Weighted averages**,\n",
    "- **Samples average**: how well predictions match across all labels per post.\n",
    "\n",
    "These metrics provide insight into model performance, especially on imbalanced symptom classes. The low scores for many classes suggest this CNN baseline struggles with rare symptoms, an expected outcome that supports the value of transformer-based models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HaQ4s06WTi95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HaQ4s06WTi95",
    "outputId": "5740e464-463d-496f-a561-12df2dafd332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        ANHEDONIA       1.00      0.04      0.08        25\n",
      "  APPETITE_CHANGE       0.00      0.00      0.00        10\n",
      " COGNITIVE_ISSUES       0.00      0.00      0.00        10\n",
      "   DEPRESSED_MOOD       0.67      0.11      0.20        70\n",
      "          FATIGUE       0.67      0.14      0.24        28\n",
      "      NO_SYMPTOMS       0.56      0.07      0.12        73\n",
      "      PSYCHOMOTOR       0.00      0.00      0.00         8\n",
      "     SLEEP_ISSUES       0.70      0.39      0.50        18\n",
      "SUICIDAL_THOUGHTS       0.65      0.39      0.49        28\n",
      "    WORTHLESSNESS       0.79      0.21      0.33        72\n",
      "\n",
      "        micro avg       0.69      0.15      0.25       342\n",
      "        macro avg       0.50      0.14      0.19       342\n",
      "     weighted avg       0.64      0.15      0.23       342\n",
      "      samples avg       0.16      0.16      0.16       342\n",
      "\n",
      "Accuracy: 0.1414141414141414\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Classification Report:\\n\",\n",
    "    classification_report(\n",
    "        y_test, predictions, target_names=mlb.classes_, zero_division=0\n",
    "    ),\n",
    ")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
